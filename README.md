# Beyond_the_buzz_Vatsal_Rajput
So, I created a machine learning model using a multi-layer perceptron (MLP) classifier. The goal of the model was to classify data based on a column called 'VERDICT' in my dataset. To do this, I used an MLP, which is a type of artificial neural network (ANN) that is composed of nodes or neurons, connected by weighted edges.The MLP in my model had three types of layers: input, hidden, and output. The input layer took in the data and each input neuron corresponded to a feature in my dataset. The output layer made the final classification, and each output neuron corresponded to a possible class or label. The hidden layer(s) were in between the input and output layers and were responsible for learning and extracting the underlying patterns in the data.

I specified that my MLP had two hidden layers with 50 and 25 neurons, respectively. The activation function used in each neuron was 'relu', which stands for rectified linear unit. This is a common activation function used in ANNs that helps the network learn nonlinear relationships between the features and the labels.The solver used in my MLP was 'adam', which is a stochastic gradient-based optimizer that is computationally efficient and requires little memory. The random state was set to 42 to ensure that the model was reproducible.

I split my dataset into training and test data using the train_test_split() function from the scikit-learn library. I trained the model on the training data using the fit() function and made predictions on the test data using the predict() function. I evaluated the performance of my model on the test data using the accuracy_score() function.Finally, I created a new DataFrame to store the predictions and saved them to a CSV file using the to_csv() function. Overall, my MLP classifier model was able to accurately classify the data based on the 'VERDICT' column in my dataset.
